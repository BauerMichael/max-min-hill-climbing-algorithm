\input{report_settings.tex} % Importiere die Einstellungen aus der Präambel
% hier beginnt der eigentliche Inhalt

\usepackage{geometry}
\geometry{tmargin=2cm,bmargin=3cm,lmargin=2cm,rmargin=2cm}

\usepackage{tikz}
\usetikzlibrary{arrows}

\begin{document}
% \pagenumbering{Roman} % große Römische Seitenummerierung
\pagestyle{empty}

% Titelseite
\clearscrheadings\clearscrplain

\begin{center}
\includegraphics[width=6cm]{img/uniR.png}

\begin{huge}
UNIVERSITÄT REGENSBURG
\vspace{10mm}
\end{huge}

{\Large \textbf{Institute of Genomics \& Practical Bioinformatics}}
\vspace{0mm}

{\Large Master of Science Computational Science}

\vspace{10mm}
\begin{huge}
The max-min-hill-climbing algorithm
\end{huge}

\vspace{10mm}

\begin{Large}
Report
\end{Large}

\begin{large}
in practical Bioinformatics
\end{large}

\vspace{5mm}
\begin{small}
by
\end{small}

\begin{large}
Michael Bauer
\end{large}

\begin{small}
Matrikelnummer: 152 8558
\end{small}

\vspace{1cm}
\begin{tabular}{ll}
{\bf Tutor:} &Dr. Giusi Moffa\\
{\bf Adviser:} &Prof. Dr. Rainer Spang\\
{\bf Date:} &\today\\
\end{tabular}

\end{center}
\clearpage


\pagestyle{useheadings} % normale Kopf- und Fußzeilen für den Rest

\tableofcontents
\listoffigures
\listoftables

\chapter{Abstract}

In this report we present a new implementation of the max-min-hill-climbing algorithm (MMHC) for R, first stated in \cite{TBA}. It combines both: greedy search and constraint-based learning techniques. We will discuss those two methods seperately and how they effect running time. We also want to work out the importance of this algorithm. The main goal of it is to reconstruct Bayesian networks from estimated data. Bayesian networks play a great role in science, economics, sports and many more fields where the observational data can get extremely big. It is not the first time R provides this algorithm but we come up by using RCPP (C++ interface for R) for our implementation to have a better chance to deal with big data. Since running time is getting more important we tried to improve it for this algorithm and beat the existing one.

\chapter{Introduction}

The max-min-hill-climbing algorithm is one of the state of the art algorithms in statistical computing. The primal aim of this algorithm is reconstructing BN out of estimated data. A Bayesian network is a Directed Acyclic Graph (DAG) whose nodes are random variables and eges represent conditional dependencies. If two random variables are connected they are said to be dependent. If there is no connection they are said to be conditional independent. BNs are more important than one can imagine. They play a great role in everdays life. For example \cite{NBBCW} use them to predict the effect of missense mutations on the protein function. But not only medical science uses Bayesian networks. Another example where scientists used them was football. In \cite{PKA} they refer to an article where european football clubs tried to predict injuries of their players depending on BNs. With a simple Google search you may also find the prediction of stock exchanges and many more. Wikipedia provides a simple but descriptive example which illustrates BNs in a smooth way.

\bild{BNexample}{8cm}{A simple example of a Bayesian network.}{source: \url{http://en.wikipedia.org/wiki/Bayesian\_network\#mediaviewer/File:SimpleBayesNetNodes.svg}}

Reconstructing those networks is not easy, more precisely it is a np-hard problem. It is not only the amount of data which leads to a bad running time, also the dependencies between nodes can slow the code down.\\
In the first step of this algorithm we try to reconstruct the skeleteon of the graph. Therefor we iterate over all variables - we select one variable (we call it "target" $\mat{T}$) in each iteration step - and find those variables which are dependent to the selected one. The more variables we find the longer a single iteration takes. The dependent variables are then said to be a parent or a child of $\mat{T}$. It may happen that there are false positive ones in our set (which we will call $\mat{CPC}$). For this reason we have to check again if the parents/children in the set really belong to our selected variable $\mat{T}$. The relation between $\mat{T}$ and its parents/children is symmetric. That means for a target $\mat{T}$ and $\mat{A} \in \mat{CPC}_{T}$ it follows:

\begin{equation}
	\mat{T} \longleftrightarrow \mat{A} \Longleftrightarrow \mat{A} \longleftrightarrow \mat{T} \label{eq.symmetric}
\end{equation}

for a target $\mat{A}$ and $\mat{T} \in \mat{CPC}_{A}$. Since this relation holds we have to check in a second step if this symmetrie is fullfild. For that we check for every $\mat{X} \in \mat{CPC}_{T}$ if $\mat{T} \in \mat{CPC}_{X}$.\\
Though this is a great approach, we are interested in the whole Directed Acyclic Graph. The second part of the algorithm will then take this skeleton and add directed edges to it such that it does not become cyclic and is fully directed. We will see that this is based on one formula which is not complicated to understand but extremely tricky for implementation. Once we observe the Bayesian network from our data we then can look at the running time of the algorithm and where the time gets lost but also where we optimized to save time. But more important for us was to beat the existing algorithm for R (part of the "bnlearn" package). The goal for us was to be faster. So after a brief discussion of our implementation we will see if it was possible to optimize the code with RCPP to beat the "bnlearn" algorithm.

\chapter{Background}

Before we are able to analyze our implementation and talk about it in detail we need some mathematical background. In this section we fully follow \cite{TBA}[p. 5-7]. For the proofs of the Lemmas and Theorems we also reference to this paper.

	\section{Notation}

		We introduce our notation which is completely consistent to \cite{TBA}.\\
		We denote
		\begin{enumerate}
			\item variables with an upper-case letter (e.g., $A, V_{i}$),
			\item a state or a value of that variable by the same lower-case letter (e.g., $a, v_{i}$),
			\item a set of variables by upper-case bold face (e.g., $\mat{Z}, \mat{Pa}_{i}$),
			\item an assignment of state or value to each variable in the given set with the corresponding lower-case bold-face letter (e.g., $\mat{y}, \mat{pa}_{i}$),
			\item special sets of variables (e.g. the set of all variables $\mathcal{V}$) with calligraphic fonts.
		\end{enumerate}

	\section{Definition (conditional independence)} \label{s.Def1}
	
		Two variables $X$ and $Y$ are conditionally independent given $\mat{Z}$ with respect to a probability distribution $P$, denoted as $Ind_{P}(X; Y|\mat{Z})$, if for all $x, y, \mat{z}$ where $P(\mat{Z} = \mat{z}) > 0$,

		\begin{equation}
			P(X = x, Y = y|\mat{Z} = \mat{z}) = P(X = x|\mat{Z} = \mat{z})P(Y = y|\mat{Z} = \mat{z})
		\end{equation}
		or
		\begin{equation}
			P(X , Y|\mat{Z}) = P(X|\mat{Z})P(Y|\mat{Z})
		\end{equation}
		for short. If $X, Y$ are dependent given $\mat{Z}$ we denote $Dep_{P}(X; Y|\mat{Z}$.

	\section{Definition (Bayesian network)} \label{s.Def2}

		Let $P$ be a discrete joint probability distribution of the random variables in some set $\mathcal{V}$ and $\mathcal{G} = <\mathcal{V}, E>$ be a Directed Acyclic Graph (DAG). We call $<\mathcal{G}, P>$ a (discrete) \textit{Bayesian network} if $<\mathcal{G}, P>$ satisfies the Markov condition.

	\section{Definition (Markov condition)} \label{s.Def3}

		Any node in a Bayesian network is conditionally independent of its non-descendants, given its parents.\\

	\section{Explanation}
		With those definitions we have our first concept we will discuss briefly. We will explain the definitions by using the following picture:
		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=2pt,auto,node distance=5cm,
			                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

			  \node[main node] (1) {Z};
			  \node[main node] (2) [below left of=1] {X};
			  \node[main node] (3) [below right of=1] {Y};

			  \path[every node/.style={font=\sffamily\small}]
			    (1) edge node [left] {} (3)
			    	edge node [left] {} (2);
			\end{tikzpicture}
		\end{center}

		The Markov condition states that $X$ and $Y$ given $\mat{Z}$ must be conditionally independent. This comes from the fact that $X$ is a non-descendant of $Y$ and vice versa and $\mat{Z}$ is a parent of both nodes. By fullfilling this condition we get from \autoref{s.Def2} that this graph is a Bayesian network and with \autoref{s.Def1} we have: $P(X , Y|\mat{Z}) = P(X|\mat{Z})P(Y|\mat{Z})$.

	\section{Defintion (collider)} \label{s.Def4}

		A node $W$ of a path $p$ is a \textit{collider} if $p$ contains two incomming edges into $W$.

	\section{Definition (blocked path)} \label{s.Def5}

		A path $p$ from node $X$ to node $Y$ is \textit{blocked} by a set of nodes $\mat{Z}$, if there is a node $W$ on $p$ for which one of the following two conditions hold:

		\begin{enumerate}
			\item $W$ is not a collider and $W \in \mat{Z}$, or
			\item $W$ is a collider and neither $W$ or its descendants are in $\mat{Z}$ \cite{P88}
		\end{enumerate}

	\section{Definition (d-seperation)} \label{s.Def6}

		Two nodes $X$ and $Y$ are \textit{d-seperated} by $\mat{Z}$ in graph $\mathcal{G}$ (denoted as $Dsep_{\mathcal{G}}(X;Y|\mat{Z})$) if and only if every path from $X$ to $Y$ is blocked by $\mat{Z}$. Two nodes are \textit{d-connected} if they are not \textit{d-seperated}.

	\section{Definition (faithful)} \label{s.Def7}

		If all and only the conditional independencies true in the distribution $P$ are entailed by the Markov condition applied to $\mathcal{G}$, we will say that $P$ and $\mathcal{G}$ are \textit{faithful to each other} (\cite{SGSN}). Furthermore, a distribution $P$ is \textit{faithful} if there exists a graph $\mathcal{G}$, to which it is faithful.

	\section{Definition (faithfulness condition)} \label{s.Def8}

		A Bayesian network $<\mathcal{G}, P>$ satisfies the \textit{faithfulness condition} if $P$ embodies only independencies that can be represented in the DAG $\mathcal{G}$ (\cite{SGSN}). We will call such a Bayesian network a \textit{faithful network}.

	\section{Theorem} \label{s.Theorem3}

		In a faithful Bayesian network $<\mathcal{G}, P>$ the following equivalence holds (\cite{P88})

		\begin{equation}
			Dsep_{\mathcal{G}} (X;Y|\mat{Z}) \Longleftrightarrow Ind_{P} (X;Y|\mat{Z})
		\end{equation}

	\section{Remark and Explanation}

		\textbf{Remark:} For the rest of this report we assume faithfulness of the networks to learn. For this reason we don't want to explain the corresponding definitions in detail. Just note, that the definitions are neccessary for mathematical correctness.

		\textbf{Explanation:} The definition of a collider already tells everything about it. To illustrate a collider, we have:

		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=2pt,auto,node distance=5cm,
			                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

			  \node[main node] (1) {Z};
			  \node[main node] (2) [left of=1] {X};
			  \node[main node] (3) [right of=1] {Y};

			  \path[every node/.style={font=\sffamily\small}]
			    (2) edge node [left] {} (1)
			    (3) edge node [left] {} (1);
			\end{tikzpicture}
		\end{center}

		Here $Z$ is a \textit{collider} because it has two incoming edges. In this case if we just look for $P(X;Y|\{\})$, the path between $X$ and $Y$ would be blocked and for this $X$ and $Y$ are \textit{d-seperated}. If we look for $P(X;Y|\mat{Z})$, then this path is not blocked and we state that $X$ and $Y$ are \textit{d-connected}.\\
		Because of \autoref{s.Theorem3} and the faithfulness assumptions we state for the rest of our report that the terms d-seperation and conditional independence are equivalent. With this we already know that $X$ and $Y$ are conditional dependent given $\mat{Z}$ in the example above. This brings us a big step closer to learn the structure of a Bayesian network from observational data. Before we start looking at the algorithms, we want to give you two other examples for d-seperation of variables.

		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=2pt,auto,node distance=2cm,
			                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

			  \node[main node] (1) {T};
			  \node[main node] (2) [left of=1] {A};
			  \node[main node, fill=orange] (3) [left of=2] {B};
			  \node[main node] (4) [left of=3] {X};
			  \node[main node] (5) [right of=1] {C};
			  \node[main node, fill=orange] (6) [right of=5] {D};
			  \node[main node] (7) [right of=6] {Y};

			  \path[every node/.style={font=\sffamily\small}]
			    (2) edge node [left] {} (1)
			    (5) edge node [left] {} (1)
			    (3) edge node [left] {} (2)
			    (4) edge node [left] {} (3)
			    (7) edge node [left] {} (6)
			    (6) edge node [left] {} (5);
			\end{tikzpicture}
		\end{center}

		If we are looking for $Ind_{P} (X;Y|\mat{Z})$ with $\mat{Z} = \{B, D\}$ we learn that $X$ and $Y$ are conditionally independent given $\mat{Z}$. In other words they are d-seperated in the path because of the following reasons:

		\begin{itemize}
			\item $T$ is a collider with $T \not\in \mat{Z}$ and blocks the path between $X$ and $Y$.
			\item The nodes $B$ and $D$ are no colliders but they are elements of $\mat{Z}$.
		\end{itemize}

		The situation becomes a bit more difficult if we take a look at the next example:

		\begin{center}
			\begin{tikzpicture}[->,>=stealth',shorten >=2pt,auto,node distance=2cm,
			                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

			  \node[main node] (1) {T};
			  \node[main node] (2) [left of=1] {A};
			  \node[main node, fill=orange] (3) [left of=2] {B};
			  \node[main node] (4) [left of=3] {X};
			  \node[main node] (5) [right of=1] {C};
			  \node[main node] (6) [right of=5] {D};
			  \node[main node] (7) [right of=6] {Y};
			  \node[main node] (8) [below of=3] {E};
			  \node[main node] (9) [below of=6] {F};
			  \node[main node, fill=orange] (10) [below of=1] {G};

			  \path[every node/.style={font=\sffamily\small}]
			    (2) edge node [left] {} (1)
			    (5) edge node [left] {} (1)
			    (3) edge node [left] {} (8)
			    (1) edge node [left] {} (10)
			    (6) edge node [left] {} (9)
			    (3) edge node [left] {} (2)
			    (4) edge node [left] {} (3)
			    (7) edge node [left] {} (6)
			    (6) edge node [left] {} (5);
			\end{tikzpicture}
		\end{center}

		We learn that the path between $X$ and $Y$ remains blocked by looking for $Ind_{P}(X;Y|\mat{Z})$ with $\mat{Z} = \{B, G\}$, i.e. $X$ and $Y$ are conditionally independent given $\mat{Z}$. If we would look at the path between $A$ and $Y$ we would learn that $A$ and $Y$ are d-connected. This comes from:

		\begin{itemize}
			\item $T$ is a collider but its descendant $G \in \mat{Z}$, i.e. $T$ would not block the path.
			\item The node $B$ is no collider but it is an element of $\mat{Z}$. For that it blocks the path.
		\end{itemize}

		So there is no element which blocks the path between $A$ and $Y$, but for $X$ and $Y$, $B$ blocks the path. \\
		As we could see, detecting conditional independence of two nodes is quite difficult in small graphs. Since we normally observe large data sets with a couple of nodes, a concept for this is needed. As we will see, statistical methods, such as hypothesis testing will be a useful friend for this task.

	\section{Definition} \label{s.Def9}

		We define the minimum association of $X$ and $T$ relative to a feature subset $\mat{Z}$, denoted as $MinAssoc(X; T | \mat{Z})$, as

		\begin{equation}
			MinAssoc (X; T | \mat{Z}) = \min_{\mat{S} \subseteq \mat{Z}} Assoc(X; T | \mat{S})
		\end{equation}

		i.e., as the minimum association achieved between $X$ and $T$ over all subsets of $\mat{Z}$. \\
		\textbf{Remark:}
		\begin{enumerate}
			\item In \autoref{img.mmpcBar} we will see this $MinAssoc$ statement again as a function. With that we measure conditional independence of $X$ and $T$ given $\mat{Z}$.
			\item For that the following equivalence holds (providing without a proof): 
				\begin{equation}
					Ind(X; T | \mat{Z}) \Longleftrightarrow (Assoc(X; T | \mat{Z} = 0).
				\end{equation}
		\end{enumerate}

\chapter{Functions of bnlearn}

	As we stated, our purpose was to implement the max-min-hill-climbing algorithm in a way that it will be faster and more efficient than the existing is. That's why we want to give you a brief introduction to the mmpc() and mmhc() functions of the "bnlearn" package. We also want to present some numbers depending on running time which show you the effectiveness of the two algorithms. Afterwards we explain our algorithm and we present our results. You will see that there will be some differences on the running time of both implementations.

	\section{mmpc(data.frame)}

		This function represents the first part of the algorithm, which returns the skeleton of the graph. You can choose between several methods of independence testing. The input is a R data frame and the return value of it is of the class "bn". With the plot function you are able to plot the whole skeleton of the graph, like:
		
		\begin{verbatim}
> graph <- mmpc(data.frame)
> plot(graph)
		\end{verbatim}

	\section{mmhc(data.frame)}

		This function is similiar to the mmpc(). The differences are, that it returns a DAG and you can additionally choose a score function which is used to direct the edges. Again you execute this with:

		\begin{verbatim}
> graph <- mmhc(data.frame)
> plot(graph)
		\end{verbatim}

\chapter{The max-min-hill-climbing algorithm}

	We now want to go into the implementation of our algorithm. First of all we want you present the pseudo code and then talk about it. Afterwards we present the statistical methods behind the algorithm and how they effect running time. In the end we want to present an example which should be reconstructed by our algorithm.

	\section{max-min-hill-climbing algorithm}

		\bild{MaxMinHillClimb-004}{12cm}{The pseudo code of the MMHC algorithm. Line 2-4 represent the loop over all nodes calling the MMPC function. At line 5 the scoring starts.}{source: The max-min hill-climbing Bayesian network structure learning algorithm, page 14.} \label{img.mmhc}
		% \begin{eqnarray}
		% 	&&\textnormal{function MMHC } (\mathcal{D}) \textnormal{ \#input: data } \mathcal{D} \notag \\
		% 		&&\hspace{10mm} \textnormal{for every variable } X \in \mathcal{V} \textnormal{ do } \notag \\
		% 			&&\hspace{10mm}\hspace{10mm} \mat{PC}_{X} = MMPC(X, \mathcal{D}) \notag \\
		% 		&&\hspace{10mm} \textnormal{end for} \notag \\ \notag \\
		% 		&&\hspace{10mm} \mat{A} = BDeu(\mat{PC}) \textnormal{ \# where } \mat{PC} \textnormal{ contains all } \mat{PC}_{X} \forall X \notag \\
		% 		&&\hspace{10mm} return(\mat{A}) \textnormal{ \#returns an adjacency matrix A; a DAG} \notag
		% \end{eqnarray}

		As mentioned before, the MMHC function has to parts. First we find the skeleton and then direct the edges of the skeleton graph. We first discuss the $MMPC$ (max-min parents and children) function which is called the observational data $\mathcal{D}$ in the for loop (over all possible nodes in the graph) and then we take a closer look at the scoring function starting at line 5. This function will later be stated as $BDeu$ which stands for Bayesian Dirichlet likelihood-equivalence uniform.

		\subsection{max-min parents and children (MMPC))}

			The max-min parents and children (MMPC) is the algorithm which reconstructs the graph skeleton from data. To bring you the concept of this closer, let us first present the pseudo code of it:

			\bild{MaxMinHillClimb-003}{14cm}{The pseudo code of the MMPC function. First the $\mat{CPC}$ set is computed by the $\overline{MMPC}$ function. Afterwards the false positives are erased.}{source: The max-min hill-climbing Bayesian network structure learning algorithm, page 12.} \label{img.mmpc}

			In this algorithm another function $\overline{MMPC}$ is executed. In \autoref{img.mmpcBar} this function - including the $MaxMinHeuristic$ function - is shown. Back to \autoref{img.mmpc}, we see, that $\overline{MMPC}$ is executed twice. Firstly at line 2 and secondly in the if-statement at line 4. As we stated in \autoref{eq.symmetric}, for two variables they are connected, the symmetrie holds. At line 2 we only now that some $X$ are in the set $\mat{CPC}$ for a target variable $T$, i.e. the $X$ is a parent or a child of $T$. By testing if $T$ is also a parent or child of $X$, we see if the symmetrie holds, if not, $X$ is removed from the $\mat{CPC}$ set. Let's talk about the $\overline{MMPC}$ function. First take a look at is:

			\bild{MaxMinHillClimb-000}{12cm}{Here you see both: the $\overline{MMPC}$ function and the calculation of the association between $X$ and $T$ by the $MaxMinHeuristic$ function.}{source: The max-min hill-climbing Bayesian network structure learning algorithm, page 8.} \label{img.mmpcBar}

			In this subfunction we have two important routines: the execution of $\overline{MMPC}$ and the $MaxMinHeuristic$.

			\subsubsection{The $MaxMinHeuristic$ function}

				This function finds the $X$ which maximizes the measure of association between $X$ and $T$ given the current $\mat{CPC}$ set. The current $\mat{CPC}$ set is therefor passed into the function. The return of the function is the $X$ and the value of association between $X$ and $T$ given $\mat{CPC}$. At this point, we left one important question: How do we measure this association.

			\subsubsection{The $G^{2}$ value}

				Because this algorithm is based on conditional independence testing and measuring the strength of association between two variables, we need some formulas for implementation to get this measure. We followed \cite{SGSN} and calculated the $G^{2}$ statistic, under the null hypothesis of the conditional independence holding. For that we have (from \cite{TBA}):\\
				Let $S_{ijk}^{ab\mat{c}}$ be the number of times in the data where $X_{i} = a$, $X_{j} = b$ and $X_{k} = \mat{c}$. We define in a similar fashion, $S_{ik}^{a\mat{c}}$, $S_{jk}^{b\mat{c}}$  and $S_{k}^{\mat{c}}$, then the $G^{2}$ statistic is defined as (c.f. \cite{SGSN}):

				\begin{equation}
					G^{2} := 2 * \sum_{a,b,c} S^{ab\textbf{c}}_{ijk} * ln \left( \frac{S^{ab\textbf{c}}_{ijk}*S^{\textbf{c}}_{k}}{S^{a\textbf{c}}_{ik}*S^{b\textbf{c}}_{jk}} \right),
				\end{equation}

				The $G^{2}$ statistic is asymptotically distributed as $\chi^{2}$ with appropriate degrees of freedom. To compute these degrees of freedom we use:

				\begin{equation}
					df = (|D(X_{i})| - 1)(|D(X_{j})| - 1) \prod_{X_{l} \in \mat{X}_{\mat{k}}} |D(X_{l})|,
				\end{equation}

				where $D(X_{i})$ is the domain (number of distinct values) of variable $X_{i}$. After bringing this to code, we can work with the output of this function.

			\subsubsection{How $\overline{MMPC}$ works}

				 The procedure of the $\overline{MMPC}$ function then works as follows:

				\begin{itemize}
					\item Compute the $G^{2}$ value. You observe a $Svalue$ of type $double$ value.
					\item Compute the degrees of freedom $df$.
					\item Assign the $pvalue$ to the output of the function $pchisq(Svalue, df)$.
					\item Test if the $pvalue$ is smaller than $0.05$, if yes then keep this $pvalue$, it's corresponding $Svalue$ and $X$.
					\item At the end let the $X$ join the $\mat{CPC}$ set which has the smallest $pvalue$.
					\item If two pvalues are equaled then take the variable $X$ with the higher $Svalue$.
					\item If you checked all variables over all subsets of the $\mat{CPC}$ set, stop the calculations.
				\end{itemize}

				\textbf{Hint:} At the moment you find that a target $T$ and a variable $X$ are conditionally independent, i.e. the association values equales zero, you don't need to check this connection again since you already know of their independence. The same holds for the fact, if they are dependent. This saves running time.\\
				After symmetrie testing in the $MMPC$ function, the first part of the algorithm returns all the parents and children of all variables. We realized this within a list. Every element of the list - numbered from 1 to n - stands for a variable and contains a vector which holds the parents and the children of this variable. The second part of the max-min-hill-climbing algorithm now takes this list and directs the edges from one variable to another.

		\subsection{The BDeu score}

			Before we present our realization of the BDeu score, we want to give a short definition of it partly following \cite{Ca06}.

			\subsubsection{Definition (BDeu score)}

				The Bayesian Dirichlet likelihood-equivalence uniform score (short: BDeu score) is defined as:

				\begin{equation}
					g_{BDeu}(D, G) = \sum_{i = 1}^{n} \left[ \sum_{j = 1}^{q_{i}} \left[ \log\left( \frac{\Gamma (\frac{\eta}{q_{i}})}{\Gamma (N_{ij} + \frac{\eta}{q_{i}})} \right) + \sum_{k = 1}^{r_{i}} \log \left( \frac{\Gamma (N_{ijk} + \frac{\eta}{r_{i} q_{i}})}{\Gamma (\frac{\eta}{r_{i} q_{i}})} \right) \right] \right],
				\end{equation}

				where $G$ is a graph, $D$ is the underlying data, the number of states of the variable $X_{i}$ is $r_{i}$, the number of possible configurations of the parent set $Pa_{G}(X_{i})$ of $X_{i}$ is $q_{i}$, with $q_{i} = \prod_{X_{j} \in Pa_{G}(X_{i})} r_{j}$, $w_{ij}, j = 1,...,q_{i}$ represents a configuration of $Pa_{G}(X_{i})$, $N_{ijk}$ is the number of instances in the data set $D$ where the variable $X_{i}$ takes the value $x_{ik}$ and the set of variables $Pa_{G}(X_{i})$ take the value $w_{ij}$, $N_{ij}$ is the number of instances in the data set where the variable in $Pa_{G}(X_{i})$ take their $j-th$ configuration $w_{ij}$, with $N_{ij} = \sum_{k = 1}^{r_{i}} N_{ijk}$, $N_{ik}$ is the number of instances in $D$ where the variable $X_{i}$ takes its $k-th$ value $x_{ik}$ and therefor $N_{ik} = \sum_{j = 1}^{q_{i}} N_{ijk}$ and the total number of instances in $D$ is $n$.

			\subsubsection{Explanation}

				Of course, this definition needs some explanation. In simple words this formula takes a graph and returns a score. That is what we need for our computations. We are seeking for the graph with the highest score. But first of all back to the calculation of the score. To compute the sums you just have to know how to get all those values explained above. Let us give you a short overview over all those variable:

				\begin{itemize}
					\item \textbf{eta}: We set this value to 1 - the most common setting. There is no rule which value is the best and one could find many papers which try to find the "best" eta. If you are interested in that we recommend you \cite{SKM}
					\item \textbf{n}: The number of variables in our BN.
					\item $\boldsymbol{r_{i}}$: How many states the $i-th$ variable can take.
					\item $\boldsymbol{q_{i}}$: The product of all states of the parent's variables of the $i-th$ variable, e.g. if node $X$ has two parents $Y$ and $Z$ $q_{X} = r_{y} \cdot r_{z}$.
					\item $\boldsymbol{w_{ij}}$: This is a configuration of the parents of a certain variable, i.e. recall $X$ with parents $Y, Z$ and we assume that the states of $Y, Z$ are binary. Then $w_{ij}$ can have four different configurations: $(0; 0), (0; 1), (1; 0), (1; 1)$.
					\item $\boldsymbol{N_{ijk}}$: Counts how often a variable $X_{i}$ takes the value $x_{ik}$ and its parents take the configuration $w_{ij}$.
					\item $\boldsymbol{N_{ij}, N_{ik}}$: Is the calculation of the sums over the depending $N_{ijk}$ values from above.
				\end{itemize}

			As already mentioned this function takes a graph and returns a value. This value should be the best score which can be achieved depending on the list returned by the $MMPC$ algorithm. For this we take an empty graph, i.e. we have all our nodes but no edges, and compute the score of this empty graph. Then we choose by random one node/variable $X$ and add an edge $X \longrightarrow Y$, if $Y$ is a parent/child of $X$. This we know from our $PC$ set, returned by $MMPC$. We compute the score again and if the new score is higher than the one of the empty graph, this score is saved and the edge stays. If it is not higher, the edge will be removed. We also apply the operations "revers edge" and "delete edge" to the graph in a similar fashion. If the score reaches a maximum we determine the search and return the "best" graph. The word best is in quotes, because randomness in our data ensures that we find the graph with the best score, but this must not be the correct one.

	\section{Introduction to an example}

		We now want to talk about the main issue we had when implenting this algorithm. We wanted to provide code which is valid and beat the running time of the functions of the bnlearn package. Our comparisons depend on a data set which is build from a self written function. The rules to create these data are taken from \cite{KoFr}. All our benchmarks and comparisons between our implementation and the bnlearn package depend on this data. For that reason we want to introduce it in the following section.

		\subsection{Student data frame}

			The following graph is the one where we started. Normally you don't start with a graph. You start with data and end up with a graph. In our case we needed a posibility to test if the code works properly. The output of the $MMHC$ should return this graph or a one which is likely to this.

			\bild{example}{16cm}{This graph should later be returned from the $MMHC$ algorithm.}{Picture of my first underlying example.} \label{img.exampleGraph}

			The probabilities and rules in this graph are computed by a R function which you find in our package. We won't provide further information here.\\

	\section{Computational effort}

		We decided to write our algorithm object oriented. With this we save a lot of running time. We have a second implementation - which will not be provided - that is written procedural. So before we will see, if our algorithm could beat the bnlearn package, we want to present the differences depending on running time between object oriented and procedural programming style. Of course, this comparison only holds for this case. Somebody else could have a greater effort on this by procedural programming. \\
		As we saw above we have five variables. For this example case we computed 10,000 observations, i.e. we have a R data frame $df \in \mathbb{N}^{10000 \times 5}$, where all nodes have binary values $1, 2$ except the node holding the grade. This has three states: $1, 2, 3$.\\ \\

		The first comparison we want to show is between the $MMPC$ version where $C\$mmpc()$ is the object oriented and $MMPC(mat, 0.05)$ the procedural programming version:

		\begin{verbatim}
df <- student(10000)
bm <- benchmark(C$mmpc(), MMPC(mat, 0.05),
                columns = c("test", "elapsed", "relative"),
                replications = 1)
print(bm)
             test elapsed relative
1        C$mmpc()   0.043    1.000
2 MMPC(mat, 0.05)   0.148    3.442
		\end{verbatim}

		Clearly, the object oriented version is faster than the other. By comparing only the BDeu scoring we observe:

		\begin{verbatim}
df <- student(10000)
bm <- benchmark(C$mmpc(), MMPC(mat, 0.05),
                columns = c("test", "elapsed", "relative"),
                replications = 1)
-27812.9 # score returned by BDeu(...)
-27812.9 # score returned by C$mmpc()
print(bm)
                          test elapsed relative
2 BDeu(mat, PC, as.integer(5))   1.419    8.446
1                     C$mmhc()   0.168    1.000
		\end{verbatim}

		At this point it becomes clear, why we focused on our object oriented version. To complete this we present the benchmark of both by running the full algorithms. We also present the graph which is returned by the computations.

		\begin{verbatim}
df <- student(10000)
bm <- benchmark(MMHC_oop(df), MMHC_pp(df),
                columns = c("test", "elapsed", "relative"),
                replications = 1)
-27619.2 # score of the graph returned by MMHC_pp(df)
-27619.2 # score of the graph returned by MMHC_oop(df)
print(bm)
          test elapsed relative
1 MMHC_oop(df)   0.253    1.000
2  MMHC_pp(df)   2.204    8.711
		\end{verbatim}

		For plotting the graph we used the "igraph" R package. The resulting graph is then:

		\bild{graph}{16cm}{The graph returned by both functions looks like the one we started with.}{Resulting graph after running the algorithm.} \label{img.resultingGraph}

		This section also showed that the $MMPC$ algorithm is much faster then the $BDeu$ score. This will play a great role in the next chapter.


\chapter{Beating bnlearn}

	Beating the bnlearn was a very challenging and difficult task. This package was developed over years. It was a PhD thesis project which went over at least one year. We only had three months for this task. But with some tricks and computational knowledge we were able to implement an algorithm which is fast and valid. The question now is, if we beated the bnlearn package and the answer is no. This comes from the fact, that the bnlearn package has a very smooth and kind of constant running time. We guessed that they were precomputing some values and then just look them up. We also tried this method, but it failed. In the end it sounds like we mist our goal, but that is not the case. As we will see our running time is also quite good and developing goes on. We will also release a package for our algorithm, because for less number of observations, i.e. up to 7,500, our $MMPC$ is a bit faster. In some computiations on other machines, e.g. a Mac Book Pro, our algorithm is extremely good, only bnlearn is a bit better.\\

	Now, let's take a look at the running times. First of all we took a range of observations from 1,000 up to 20,000 for $MMPC$ and 10,000 for $MMHC$ respectively in steps of 1,000. We then ran our benchmark 10 times, added up the running times and divided by 10 to avoid large peaks in our plots. What you see on the picture is the number of observations against running time in seconds:

	\bild{10timePlot}{16cm}{From 1,000 to 7,500 observations our algorithm (red line) is quite fast. Above this number bnlearn one (green line) is much faster.}{Comparing our implementation with bnlearn for $MMPC$.}

	But if you look at the right boundary of the function you discover that our implementation only needs about 0.08 seconds to find the skeleton of a graph out of 100,000 values. But also the running time for the $MMHC$ algorithm is not bad. About 1.4 seconds for the biggest data frame. To beat bnlearn with this is extremely difficult. They only need about 0.1 seconds and this is amazing.

	\bild{compareMMHC}{16cm}{Hear you see that our algorithm (red line) grows linearly where as the bnlearn one (green one) is constant.}{Comparing our implementation with bnlearn for $MMPC$.}


% \chapter{Computational aspects}

\chapter{Conclusion}

	My conclusion is that I don't have a conclusion :)

\chapter{Thanks}

	I want to thank Giusi Moffa for her great support. Because of you I found a bigger pashion for R and also statistics. This 


\begin{thebibliography}{56}

\bibitem[TBA]{TBA}
Ioannis Tsamardinos, Laura E. Brown, Constantin F. Aliferis,\\
The max-min hill-climbing Bayesian network structure learning algorithm,\\
Springer Science + Business Media,
Inc. 2006
\bibitem[NBBCW]{NBBCW}
Chris J. Needham1, James R. Bradford, Andrew J. Bulpitt, Matthew A. Care and David R. Westhead,\\
Predicting the effect of missense mutations on protein function: analysis with Bayesian networks,\\
http://www.biomedcentral.com/1471-2105/7/405
\bibitem[PKA]{PKA}
http://www-ekp.physik.uni-karlsruhe.de/\~zupanc/WS1011/docs/Datenanalyse2010\_3.pdf
\bibitem[P88]{P88}
Pearl,
1988
\bibitem[SGSN]{SGSN}
Spirtes, Glymour \& Scheines,
1993, 2000; \\
Neapolitan,
2003
\bibitem[Ca06]{Ca06}
Luis M. de Campos,\\
A Scoring Function for Learning Bayesian Networks based on Mutual
Information and Conditional Independence Tests,\\
Journal of Machine Learning Research 7, 2006
\bibitem{SKM}[SKM]
On Sensitivity of the MAP Bayesian Network Structure to the Equivalent Sample Size Parameter,\\
Tomi Silander and Petri Kontkanen and Petri Myllymäki,\\
UAI, 2007
\bibitem[KoFr]{KoFr}
Daphne Koller, Nir Friedman,\\
Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning),\\
The MIT Press,\\
First edition (16. November 2009)

\end{thebibliography}

\end{document}


			% \begin{eqnarray}
			% 	&&\textnormal{function MMPC } (T, \mathcal{D}) \textnormal{ \#input: target } T, \textnormal{ data } \mathcal{D} \notag \\
			% 		&&\hspace{10mm} \textnormal{\# Forward Phase:} \notag \\
			% 		&&\hspace{10mm} \mat{CPC} = \emptyset \notag \\
			% 		&&\hspace{10mm} \textnormal{while } \mat{CPC} \textnormal{ is changing } \{ \notag \\
			% 			&&\hspace{10mm}\hspace{10mm} \textnormal{Tuple<X, assoc(X,T)> } = MaxMinHeuristic(T, \mat{CPC}) \notag \\
			% 			&&\hspace{10mm}\hspace{10mm} \textnormal{if (assoc(X,T) } \ne \textnormal{ 0) } \{ \notag \\
			% 				&&\hspace{10mm}\hspace{10mm}\hspace{10mm} \mat{CPC} = \mat{CPC} \cup X \notag \\
			% 			&&\hspace{10mm}\hspace{10mm} \} \notag \\
			% 		&&\hspace{10mm} \} \notag \\
			% 		\notag \\
			% 		&&\hspace{10mm} \textnormal{\# Backward Phase:} \notag \\
			% 		&&\hspace{10mm} \textnormal{for all } X \in \mat{CPC} \textnormal{ do } \notag \\
			% 			&&\hspace{10mm}\hspace{10mm} \textnormal{if } \exists \mat{} \ne \textnormal{ 0) } \{ \notag \\
			% 			&&\hspace{10mm}\hspace{10mm} \mat{PC}_{X} = MMPC(X, \mathcal{D}) \notag \\
			% 		&&\hspace{10mm} \textnormal{end for} \notag \\ \notag \\
			% 		&&\hspace{10mm} \mat{A} = BDeu(\mat{PC}) \textnormal{ \# where } \mat{PC} \textnormal{ contains all } \mat{PC}_{X} \forall X \notag \\



			% 		&&\hspace{10mm} \textnormal{end for} \notag \\ \notag \\
			% 		&&\hspace{10mm} \mat{A} = BDeu(\mat{PC}) \textnormal{ \# where } \mat{PC} \textnormal{ contains all } \mat{PC}_{X} \forall X \notag \\
			% 		&&\hspace{10mm} return(\mat{A}) \textnormal{ \#returns the parents and children of } T \notag
			% \end{eqnarray}